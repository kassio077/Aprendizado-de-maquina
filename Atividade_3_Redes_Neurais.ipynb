{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atividade_3_Redes_Neurais.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15nazkaGlrvOseVx8STn9mcZ0vQRvJWKr",
      "authorship_tag": "ABX9TyPsC+KhpYhZpJBcIrQgn8AN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kassio077/Aprendizado-de-maquina/blob/master/Atividade_3_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq4LvFCugkOU",
        "colab_type": "text"
      },
      "source": [
        "# Classificando dodos de detecção de intrusão na rede com Redes Neurais Artificiais\n",
        "\n",
        "O Dataset consiste em informações de um ambiente simulado de ataques a uma LAN (Network de Área Local) Militar. A base de dados é composta por 42 atributos e 25192 instâncias que estão classificadas como:\n",
        "\n",
        "\n",
        "1.   anormaly\n",
        "2.   normal\n",
        "\n",
        "Os atributos descrevem se uma conexão representa ou não um ataque de intruso a rede.\n",
        "\n",
        "Link para o dataset: [link text](https://www.kaggle.com/sampadab17/network-intrusion-detection?select=Train_data.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHeZLUgnQykM",
        "colab_type": "text"
      },
      "source": [
        "# 1. Carregando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn06M4-SQ7YV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9c6a3603-030d-47b5-e2e1-a39718d72f6e"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "dados = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Train_data.csv')\n",
        "\n",
        "dados.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>150</td>\n",
              "      <td>25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>255</td>\n",
              "      <td>26</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>anomaly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>30</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration protocol_type  ... dst_host_srv_rerror_rate    class\n",
              "0         0           tcp  ...                     0.00   normal\n",
              "1         0           udp  ...                     0.00   normal\n",
              "2         0           tcp  ...                     0.00  anomaly\n",
              "3         0           tcp  ...                     0.01   normal\n",
              "4         0           tcp  ...                     0.00   normal\n",
              "\n",
              "[5 rows x 42 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z9TE3ElRYhG",
        "colab_type": "text"
      },
      "source": [
        "# 2. Limpeza e organização dos dados\n",
        "\n",
        "* Alguns atributos não estão contribuindo para a classificação, pois estão com valores comuns para as instâncias. Por isso aplicamos a remoção de alguns deles.\n",
        "\n",
        "* O atributo que representa a classificação foi transformado em numérico para ser utilizado em algumas técnicas de análise.\n",
        "\n",
        "* O atributo **service** foi removido porque apresentava valores muito específicos para cada instância."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvC4hAXdRreH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remoção dos atributos\n",
        "dados = dados.drop(columns=['service','land','wrong_fragment','urgent','hot','num_failed_logins',\n",
        "                            'num_compromised','root_shell','su_attempted','num_root',\n",
        "                            'num_file_creations','num_shells','num_access_files',\n",
        "                            'num_outbound_cmds','is_host_login','is_guest_login'])\n",
        "\n",
        "#Transformando o atributo categorico em numérico.\n",
        "dados['class'] = dados['class'].replace(['anomaly','normal'],[1,0])\n",
        "\n",
        "dados['protocol_type'] = dados['protocol_type'].replace(['tcp','udp','icmp'],['001','010','100'])\n",
        "dados['flag'] = dados['flag'].replace(['SF','S0','REJ','RSTR','SH','RSTO','S1','RSTOS0','S3','S2','OTH'],\n",
        "                                      ['0001','0010','0100','1000','1111','0011','0110','0101','1100','1110','0111'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1UbhLOXRuOc",
        "colab_type": "text"
      },
      "source": [
        "# 3. Preparação dos dados para o classificador\n",
        "\n",
        "* Normalizando os atributos numéricos, através da re-escala usando máximo e mínimo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4rGvB4cR7VJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "1c44d23d-941b-40e4-ba38-2b8f847d27f9"
      },
      "source": [
        "dados['duration'] = dados['duration']/dados['duration'].max()\n",
        "\n",
        "atributos_categoricos = dados.iloc[:,0:3]\n",
        "\n",
        "#Dataframe apenas com as colunas de atributos numéricos.\n",
        "atributos_numericos = dados.iloc[:,3:25] \n",
        "#Aplicando a re-escala.\n",
        "atributos_numericos = (atributos_numericos - atributos_numericos.min())/(atributos_numericos.max()-atributos_numericos.min())\n",
        "\n",
        "atributos_numericos.head(100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.286320e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.824902e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.077927e-07</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.213394e-07</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056863</td>\n",
              "      <td>0.060784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>8.029675e-06</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.952941</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2.672192e-07</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.027451</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>6.785272e-07</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005882</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>3.851100e-07</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250980</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       src_bytes  dst_bytes  ...  dst_host_rerror_rate  dst_host_srv_rerror_rate\n",
              "0   1.286320e-06   0.000000  ...                  0.05                      0.00\n",
              "1   3.824902e-07   0.000000  ...                  0.00                      0.00\n",
              "2   0.000000e+00   0.000000  ...                  0.00                      0.00\n",
              "3   6.077927e-07   0.001583  ...                  0.00                      0.01\n",
              "4   5.213394e-07   0.000082  ...                  0.00                      0.00\n",
              "..           ...        ...  ...                   ...                       ...\n",
              "95  8.029675e-06   0.000064  ...                  0.00                      0.00\n",
              "96  2.672192e-07   0.000020  ...                  0.00                      0.00\n",
              "97  6.785272e-07   0.000146  ...                  0.00                      0.00\n",
              "98  3.851100e-07   0.000020  ...                  0.00                      0.00\n",
              "99  0.000000e+00   0.000000  ...                  0.00                      0.00\n",
              "\n",
              "[100 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs1kf1GnnWPi",
        "colab_type": "text"
      },
      "source": [
        "* Separando os atributos descritores do atributo classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhUPCeAnaux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "72136ff3-14ab-4b69-d700-fc281e9b5b3a"
      },
      "source": [
        "#Subconjunto dos atributos descritores\n",
        "atributos_descritores = pd.merge(atributos_categoricos,atributos_numericos, left_index=True, right_index=True)\n",
        "atributos_descritores.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0001</td>\n",
              "      <td>1.286320e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>010</td>\n",
              "      <td>0001</td>\n",
              "      <td>3.824902e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.101961</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0001</td>\n",
              "      <td>6.077927e-07</td>\n",
              "      <td>0.001583</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.007843</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0001</td>\n",
              "      <td>5.213394e-07</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056863</td>\n",
              "      <td>0.060784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0100</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.074510</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227451</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.527451</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.013725</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050980</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration protocol_type  ... dst_host_rerror_rate  dst_host_srv_rerror_rate\n",
              "0       0.0           001  ...                 0.05                      0.00\n",
              "1       0.0           010  ...                 0.00                      0.00\n",
              "2       0.0           001  ...                 0.00                      0.00\n",
              "3       0.0           001  ...                 0.00                      0.01\n",
              "4       0.0           001  ...                 0.00                      0.00\n",
              "5       0.0           001  ...                 1.00                      1.00\n",
              "6       0.0           001  ...                 0.00                      0.00\n",
              "7       0.0           001  ...                 0.00                      0.00\n",
              "8       0.0           001  ...                 0.00                      0.00\n",
              "9       0.0           001  ...                 0.00                      0.00\n",
              "\n",
              "[10 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7uivNyjnmoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0d0aa181-b7a6-4833-af23-6d51e1aeb019"
      },
      "source": [
        "#Subconjunto do atributo class\n",
        "atributo_classificador = dados['class']\n",
        "atributo_classificador.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDuL_1MinwYH",
        "colab_type": "text"
      },
      "source": [
        "* Aplicando os subconjuntos de dados para treino e teste do classificador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S946GUHn6Ao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "bc26bf11-6874-44e5-fdc9-e269b91dd094"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dados_descritores_train, dados_descritores_test,dados_classificador_train, dados_classificador_test = train_test_split(atributos_descritores,atributo_classificador, test_size=0.2)#random_state=42\n",
        "\n",
        "#Subconjunto das instâncias com atributos descritores para Treino\n",
        "dados_descritores_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.480392</td>\n",
              "      <td>0.037255</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2527</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.439216</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18950</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0001</td>\n",
              "      <td>1.991045e-06</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.631373</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22728</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0010</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23675</th>\n",
              "      <td>0.0</td>\n",
              "      <td>001</td>\n",
              "      <td>0001</td>\n",
              "      <td>8.750119e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.001961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023529</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       duration protocol_type  ... dst_host_rerror_rate  dst_host_srv_rerror_rate\n",
              "223         0.0           001  ...                  0.0                       0.0\n",
              "2527        0.0           001  ...                  0.0                       0.0\n",
              "18950       0.0           001  ...                  0.0                       0.0\n",
              "22728       0.0           001  ...                  0.0                       0.0\n",
              "23675       0.0           001  ...                  0.0                       0.0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsCbjsl5oDBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6c3c9662-6e93-4840-d06e-9e69499db899"
      },
      "source": [
        "#Valores das instâncias com atributo classificador para treino\n",
        "dados_classificador_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223      1\n",
              "2527     1\n",
              "18950    0\n",
              "22728    1\n",
              "23675    1\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1-c50CroH5c",
        "colab_type": "text"
      },
      "source": [
        "# 4. Definindo o algoritmo de classificação\n",
        "\n",
        "A partir do conjunto de dados gerados para treinar o classificador utilizando uma Rede Neural Multi-Layer Perceptron(MLP), foi determinado alguns parâmetros para a Rede Neural que consistirá em:\n",
        "* Número de neurônios por camada = 100\n",
        "* Função de ativação = logistic\n",
        "* Número de interações = 1000\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY8UVijSZub0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb1xWD4XZ2YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definindo modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnu5_lFyaG7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c116ccf5-8e4c-4014-f08a-d214835179d6"
      },
      "source": [
        "#treinando modelo\n",
        "classificador.fit(dados_descritores_train,dados_classificador_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6IQdw5jbaQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "677d7a3d-18f1-4f7e-b6d0-c8a0fbaac6f5"
      },
      "source": [
        "#realizando classificação\n",
        "classificacao = classificador.predict(dados_descritores_test)\n",
        "classificacao"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN6dl9sud7S6",
        "colab_type": "text"
      },
      "source": [
        "# 5. Avaliando o classificador\n",
        "\n",
        "Para o dataset em questão temos como valor para o atributo alvo: anormaly (**positivo**) e normal (**negativo**). Eles representam a classificação das instâncias, como uma comunicação **anormaly** (1) ou **normal** (0).\n",
        "\n",
        "* Métrica da acurácia\n",
        "\n",
        "Como os dados estão razoavelmente balanceados a métrica da acurácia corresponderá um resultado mais preciso. Após aplica-lá aos dados, o classificador obteve 97% das instâncias de teste classificadas corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qbmflstDhsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando acurácia\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5-GPmaQDqpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8e9c4ba-f295-42a1-d836-e65e4f81cfa8"
      },
      "source": [
        "acuracia = accuracy_score(dados_classificador_test,classificacao)\n",
        "acuracia"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9805516967652312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCoojMHpGeW9",
        "colab_type": "text"
      },
      "source": [
        "* Métrica da precisão\n",
        "\n",
        "Se uma instância do dataset representa uma comunicação a rede LAN como sendo uma comunicação (negativa) normal e o classificador predizer como uma instância (positiva) anomaly, representando um ataque de intrusão. Isso irá representar uma situação de falso positivo. Se for considerado como um cenário prejudicial a rede LAN, a escolha desta métrica é recomendada.\n",
        "\n",
        "O resultado do calculo da métrica é um bom resultado caso este cenário seja mais prejudicial, pois representa a porcentagem de instâncias classificadas como positivas que são relmente positivas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRpXv5MlG86q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando precisão\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Vzzvi0HlSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf0f4367-84a3-4248-f9de-01713a1f23ce"
      },
      "source": [
        "precisao = precision_score(dados_classificador_test,classificacao)\n",
        "precisao"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9846808510638297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HopCEh6II9eK",
        "colab_type": "text"
      },
      "source": [
        "* Métrica da recall\n",
        "\n",
        "Para uma instância que representa um ataque de intrusão (positivo) anomaly ser considerado pela função de classificação como uma comunicação (negativo) normal, pode trazer sérios problemas a rede LAN. Por isso a métrica da recall é mais recomendada para análise do classificador.\n",
        "\n",
        "A porcentagem de acerto usando esta métrica revela uma taxa de instâncias positivas classificadas corretamente menor, se compararmos com a metrica de precisão, consequentemente um número maior de erros de falso negativo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m3_FWpEJcqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando recall (revocação)\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W43rlzugJscD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a07cad-52e9-4751-a518-9434234b0cc4"
      },
      "source": [
        "recall = recall_score(dados_classificador_test,classificacao)\n",
        "recall"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9739057239057239"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7yfNATefuFz",
        "colab_type": "text"
      },
      "source": [
        "* Metrica F1-score\n",
        "Para acharmos uma média entre a taxa da precisão e recall, utilizamos a metrica F1-score. Seu resultado mostrou que ouve um bom balanceamento: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-PPplW6g29l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando f1-score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy-RFS3qg4G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3352b227-968c-4648-b98c-34fb9ce00f44"
      },
      "source": [
        "f1 = f1_score(dados_classificador_test,classificacao)\n",
        "f1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9792636479052053"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42-qm7RiwXc",
        "colab_type": "text"
      },
      "source": [
        "* **Curva  ROC**\n",
        "\n",
        "Utilizando a curva ROC podemos visualizar melhor a razão entre a taxa de positivos verdadeiros (TPR) e positivos falsos (FPR)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlLVJU_8lrnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotando curva roc\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT3XswKjlynl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, _ = roc_curve(dados_classificador_test,classificacao)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w9QXHn4mGBh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "244ba253-e1d9-4706-ab75-301be844d78b"
      },
      "source": [
        "plt.plot(fpr,tpr,marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h3qImKMYSFO",
        "colab_type": "text"
      },
      "source": [
        "* **Área sob a curva**\n",
        "\n",
        "Como tínhamos verificado com a metrica recall **taxa de verdadeiros positivos** a curva ROC mostra de forma gráfica a curva mais próximo de 1 no eixo y, em relação a **taxa de falsos positivos** eixo x. Confirmando um número maior de instâncias classificadas como verdadeiros positivos. O resultado desta área é calculado a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q97XMwVTllmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjYplDsZq4tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80c76396-ade4-449c-875d-7c1128314fd3"
      },
      "source": [
        "#calculando area sob a curva ROC\n",
        "auc = roc_auc_score(dados_classificador_test,classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFjcFO91vEBM",
        "colab_type": "text"
      },
      "source": [
        "* **Validação cruzada**\n",
        "\n",
        "Como os dados para as métricas anteriores utilizadas foram aleatorizados pela divisão do dataset, não podemos afirmar com certeza a qualidade deste modelo de classificador para novas instâncias que surgirem. Por isso utilizamos a validação cruzada para avaliar um número maior de subconjuntos de dados do dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQbhOQX58dZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#avaliando modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7heiA75vQbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definindo um novo classificador\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJwj9pbJ5osV",
        "colab_type": "text"
      },
      "source": [
        "A partir de 10 subconjuntos de dados do dataset foram treinados e criados os respectivos modelos de classificador, e avaliados cada um deles com um subconjunto de teste a partir da métrica da acurácia. Cada score representa a taxa de acerto de cada um deles.\n",
        "\n",
        "A média da taxa de acerto de cada modelo classificador foi de 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoI_7jfFv9Z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bda820e3-cfd6-4925-836e-4a527c7e3872"
      },
      "source": [
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,atributos_descritores,atributo_classificador,cv=10)\n",
        "scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98452381, 0.98055556, 0.98173879, 0.98570861, 0.97816594,\n",
              "       0.98570861, 0.98054784, 0.97379913, 0.98292973, 0.98253275])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bk6Es-hwm7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6761b92-e2f8-4374-8e41-4730e1807c6c"
      },
      "source": [
        "#média taxa de acerto e desvio padrão\n",
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.982, 0.003)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDxnqg7FbUWq",
        "colab_type": "text"
      },
      "source": [
        "# 6.Comparando MLP com Árvore de decisão e Random Forest\n",
        "\n",
        "* **Utilizando Validação Cruzado como método de avaliação**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj1pR1yoc9-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJnB0VDNdd4r",
        "colab_type": "text"
      },
      "source": [
        "* Árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNxmbnI2dUUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_arvore = cross_val_score(arvore,atributos_descritores,atributo_classificador,cv=10)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QmIbaHEd2gv",
        "colab_type": "text"
      },
      "source": [
        "* Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9dWJ3iNeM5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando random forest\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_floresta = cross_val_score(floresta,atributos_descritores,atributo_classificador,cv=10)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY_q1pqUhi8j",
        "colab_type": "text"
      },
      "source": [
        "* Comparando os resultados\n",
        "\n",
        "Os resultados mostraram pequenas diferenças de performance para os diferentes algoritmos de classificação. A MLP saiu com a menor porcentagem comparado aos outros classificadores, no entanto, é uma taxa satisfatória."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxrLMA4tgqgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "213ec81a-154c-4f75-923a-c2e65aa7fb1d"
      },
      "source": [
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3),round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores_floresta.mean(),3),round(scores.std(),3))\n",
        "print('MLP:', round(scores.mean(),3),round(scores.std(),3))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.993 0.001\n",
            "Random Forest:  0.996 0.003\n",
            "MLP: 0.982 0.003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyy0OOqoHy4",
        "colab_type": "text"
      },
      "source": [
        "# 7. Otimizando Parâmetros\n",
        "Foram configurados alguns parâmetros para determinar um espaço de busca, e com isso, tentar achar uma melhor performance para a MLP. Estes parâmetros indicam o número de camadas escondidas da MLP e quantidade de neurônios por camada, função de ativação, algoritmo de otimização, e número de interações."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlNWnO34Y9sY",
        "colab_type": "text"
      },
      "source": [
        "* **Random search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJjy2Lp-qood",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSeXreArq6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parâmetros pré-configurados do espaço de busca\n",
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes': [(10),(30),(80),(50,20),(100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [500,1000,2000]\n",
        "              }\n",
        "              \n",
        "]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfE2AnKDsF2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sorteando os modelos do espaço de busca\n",
        "mlp = RandomizedSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKkNRFzysOPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "42073337-46c5-4667-b578-39e95de0ca33"
      },
      "source": [
        "#Treinando os modelos\n",
        "mlp.fit(atributos_descritores,atributo_classificador)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 30, 80,\n",
              "                                                                (50, 20),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLrondZMVRPK",
        "colab_type": "text"
      },
      "source": [
        "* Melhor configuração sorteada\n",
        "\n",
        "A partir do espaço de busca e a métrica escolhida, o Random search sorteou algumas combinações de parâmetros e retornou a melhor configuração para os seguintes parâmetros:\n",
        "\n",
        "1.   Algoritmo de otimização: adam\n",
        "2.   Número de interações: 1000\n",
        "3.   Camadas escondidas: (100, 50) \n",
        "4.   Função de ativação: logistic\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPgzIFjkQoqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85d1827d-ca23-4bd0-ff4e-fb87fcaa9b0e"
      },
      "source": [
        "print(mlp.best_params_)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': (100, 50), 'activation': 'logistic'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i46omHYmWwZ6",
        "colab_type": "text"
      },
      "source": [
        "Taxa da melhor configuração avaliada pela métrica da acuracia foi de 98%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqGpzDNjRWPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9064ff8d-a9e9-4097-bb47-37bbad4eead9"
      },
      "source": [
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d84g3mFUj_WV",
        "colab_type": "text"
      },
      "source": [
        "* **Grid search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TncrYpaKwCSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOkuyrfLxf2K",
        "colab_type": "text"
      },
      "source": [
        "Para o grid search foram executados todas as combinações do espaço de busca com os parâmetros pré-configurados e a métrica da acurácia como avaliador. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gBkrvEuwE1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Definindo o espaço de busca para os modelos\n",
        "mlp = GridSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VipDUNP3wJ5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "076ab47a-d057-4c01-f7b5-520398ba45c7"
      },
      "source": [
        "#Treinando os modelos\n",
        "mlp.fit(atributos_descritores,atributo_classificador)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 30, 80, (50, 20),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [500, 1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5IZtoxDCC4",
        "colab_type": "text"
      },
      "source": [
        "* Resultados do grid search\n",
        "\n",
        "Alguns modelos não convergiram para um determinado número de interações. Em relação ao radom search, a taxa de acerto foi praticamente igual. Já os parâmetros do melhor modelo, houve diferenças como a função de ativação e o número de interações. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRFJbNjxwqox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaff0688-efee-4d6c-e228-18e495fbfb67"
      },
      "source": [
        "#Melhor combinação de parametros\n",
        "print(mlp.best_params_)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'relu', 'hidden_layer_sizes': (100, 50), 'max_iter': 500, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrulOULtwu-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56ae2d34-8b8a-47e1-bf98-03ae62a49b16"
      },
      "source": [
        "#Taxa de acerto do melhor modelo\n",
        "print(mlp.best_score_)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.985749455162791\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}